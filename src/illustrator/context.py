"""Runtime context for the manuscript illustration workflow."""

from typing import Any, Dict

from pydantic import BaseModel, Field

from illustrator.models import ImageProvider, LLMProvider


class ManuscriptContext(BaseModel):
    """Runtime configuration and context for manuscript processing."""

    # User identification
    user_id: str = Field(description="Unique identifier for the user")

    # LLM Configuration
    llm_provider: LLMProvider = Field(
        default=LLMProvider.HUGGINGFACE,
        description="Language model provider for manuscript analysis",
    )
    model: str = Field(default="anthropic/claude-3-5-sonnet-20241022", description="Primary analysis model")
    huggingface_task: str = Field(
        default="text-generation",
        description="HuggingFace pipeline task used for local inference",
    )
    huggingface_device: str | int | None = Field(
        default=None,
        description="Device identifier for HuggingFace pipelines (e.g., 'cpu', 'cuda:0', 'auto')",
    )
    huggingface_max_new_tokens: int = Field(
        default=512,
        description="Maximum tokens generated by the HuggingFace pipeline",
    )
    huggingface_temperature: float = Field(
        default=0.7,
        description="Sampling temperature for HuggingFace pipeline output",
    )
    huggingface_model_kwargs: Dict[str, Any] | None = Field(
        default=None,
        description="Additional keyword arguments passed to the HuggingFace pipeline",
    )
    huggingface_endpoint_url: str | None = Field(
        default=None,
        description="HuggingFace Inference Endpoint URL for hosted models",
    )
    huggingface_timeout: float | None = Field(
        default=None,
        description="Timeout in seconds for HuggingFace endpoint requests",
    )
    huggingface_flux_endpoint_url: str | None = Field(
        default=None,
        description="HuggingFace Inference Endpoint URL used for Flux image generation",
    )
    huggingface_image_model: str | None = Field(
        default=None,
        description="Default HuggingFace text-to-image model identifier",
    )
    huggingface_image_endpoint_url: str | None = Field(
        default=None,
        description="Optional override endpoint for HuggingFace text-to-image inference",
    )
    huggingface_image_provider: str | None = Field(
        default=None,
        description="Optional routed provider for HuggingFace text-to-image (e.g., fal-ai, replicate)",
    )

    # System prompts
    analysis_prompt: str = Field(
        default="""You are an expert literary analyst and creative director specializing in identifying the most emotionally resonant moments in fiction. Your task is to:

1. Analyze the provided chapter text for emotional peaks and valleys
2. Identify 3-5 moments with the highest emotional intensity
3. Consider narrative tension, character development, sensory details, and thematic resonance
4. For each moment, determine the dominant emotional tones and their intensity
5. Generate optimal illustration prompts that capture the essence of these moments

Current time: {time}
User preferences: {user_preferences}
Chapter context: {chapter_context}""",
        description="System prompt for chapter analysis"
    )

    illustration_prompt: str = Field(
        default="""You are a master prompt engineer for AI image generation. Your expertise spans DALL-E, Imagen4, Flux, and Seedream models.

For the given emotional moment and provider, create an optimal generation prompt that:
1. Captures the emotional essence and atmosphere
2. Includes vivid visual details from the text
3. Applies appropriate artistic style modifiers for the provider
4. Considers technical limitations and strengths of each model
5. Balances creative interpretation with textual fidelity

Provider: {provider}
Style preferences: {style_preferences}
Scene context: {scene_context}""",
        description="System prompt for illustration generation"
    )

    # Processing preferences
    image_provider: ImageProvider = Field(default=ImageProvider.DALLE, description="Default image generation provider")
    max_emotional_moments: int = Field(default=10, description="Maximum emotional moments to extract per chapter")
    min_intensity_threshold: float = Field(default=0.6, description="Minimum emotional intensity threshold")

    # Style preferences
    default_art_style: str = Field(default="digital painting", description="Default artistic style")
    color_palette: str | None = Field(default=None, description="Preferred color palette")
    artistic_influences: str | None = Field(default=None, description="Artistic influences or references")

    # API Configuration
    openai_api_key: str | None = Field(default=None, description="OpenAI API key for DALL-E")
    anthropic_api_key: str | None = Field(default=None, description="Anthropic API key for Claude")
    google_credentials: str | None = Field(default=None, description="Google Cloud credentials for Imagen4")
    google_project_id: str | None = Field(default=None, description="Google Cloud project ID for Imagen4")
    huggingface_api_key: str | None = Field(default=None, description="HuggingFace API key for language models and Flux")
    replicate_api_token: str | None = Field(default=None, description="Replicate API token for hosted image models")

    # Advanced settings
    enable_content_filtering: bool = Field(default=True, description="Enable content filtering for generated images")
    save_intermediate_results: bool = Field(default=True, description="Save analysis results during processing")
    batch_processing: bool = Field(default=False, description="Enable batch processing mode")
    # Analysis mode and concurrency
    analysis_mode: str = Field(default="scene", description="basic | scene | parallel")
    prompt_concurrency: int = Field(default=2, description="Max concurrent prompt generations")
    image_concurrency: int = Field(default=2, description="Max concurrent image generations")

    model_config = {"extra": "allow"}


# Create an alias for backwards compatibility and convenience
IllustratorContext = ManuscriptContext


def get_default_context() -> IllustratorContext:
    """Get default context with environment variables."""
    import os
    # Ensure environment variables from a nearby .env are available
    try:
        from dotenv import load_dotenv, find_dotenv
        load_dotenv(find_dotenv(), override=False)
    except Exception:
        # If dotenv isn't available or .env isn't found, proceed with process env
        pass

    # Determine preferred LLM provider based on environment configuration
    provider_value = (
        os.getenv('LLM_PROVIDER')
        or os.getenv('DEFAULT_LLM_PROVIDER')
        or ''
    ).strip().lower()
    provider = None
    if provider_value:
        try:
            provider = LLMProvider(provider_value)
        except ValueError:
            provider = None

    anthropic_key = os.getenv('ANTHROPIC_API_KEY')
    hf_endpoint_env = (os.getenv('HUGGINGFACE_ENDPOINT_URL') or '').strip()

    if hf_endpoint_env:
        provider = LLMProvider.HUGGINGFACE
    elif provider is None:
        provider = LLMProvider.ANTHROPIC if anthropic_key else LLMProvider.HUGGINGFACE

    default_model = os.getenv('DEFAULT_LLM_MODEL')
    if not default_model:
        default_model = (
            "claude-3-5-sonnet-20241022"
            if provider == LLMProvider.ANTHROPIC
            else "gpt-oss-120b"
        )

    # Ensure Anthropic models are referenced without provider prefix for LangChain init
    if provider == LLMProvider.ANTHROPIC and default_model.startswith("anthropic/"):
        default_model = default_model.split("/", 1)[1]

    huggingface_task = os.getenv('HUGGINGFACE_PIPELINE_TASK', 'text-generation')
    huggingface_device: str | int | None
    device_env = os.getenv('HUGGINGFACE_DEVICE')
    if device_env is None:
        huggingface_device = None
    elif device_env.isdigit():
        huggingface_device = int(device_env)
    else:
        huggingface_device = device_env

    hf_max_tokens = os.getenv('HUGGINGFACE_MAX_NEW_TOKENS')
    huggingface_max_new_tokens = int(hf_max_tokens) if hf_max_tokens and hf_max_tokens.isdigit() else 512

    hf_temp = os.getenv('HUGGINGFACE_TEMPERATURE')
    try:
        huggingface_temperature = float(hf_temp) if hf_temp is not None else 0.7
    except ValueError:
        huggingface_temperature = 0.7

    hf_endpoint = hf_endpoint_env or None
    if not hf_endpoint and provider == LLMProvider.HUGGINGFACE:
        hf_endpoint = f"https://api-inference.huggingface.co/models/{default_model}"

    hf_timeout_env = os.getenv('HUGGINGFACE_TIMEOUT')
    try:
        huggingface_timeout = float(hf_timeout_env) if hf_timeout_env is not None else None
    except ValueError:
        huggingface_timeout = None

    hf_flux_endpoint = os.getenv('HUGGINGFACE_FLUX_ENDPOINT_URL')
    if not hf_flux_endpoint:
        hf_flux_endpoint = "https://qj029p0ofvfmjxus.us-east-1.aws.endpoints.huggingface.cloud"

    hf_image_model = os.getenv('HUGGINGFACE_IMAGE_MODEL')
    hf_image_endpoint = os.getenv('HUGGINGFACE_IMAGE_ENDPOINT_URL')
    hf_image_provider = os.getenv('HUGGINGFACE_IMAGE_PROVIDER')

    replicate_token = os.getenv('REPLICATE_API_TOKEN')

    return IllustratorContext(
        user_id="default_user",
        llm_provider=provider,
        model=default_model,
        openai_api_key=os.getenv('OPENAI_API_KEY'),
        anthropic_api_key=anthropic_key,  # Keep API key regardless of active provider
        google_credentials=os.getenv('GOOGLE_APPLICATION_CREDENTIALS'),
        google_project_id=os.getenv('GOOGLE_PROJECT_ID'),
        huggingface_api_key=os.getenv('HUGGINGFACE_API_KEY'),
        replicate_api_token=replicate_token,
        huggingface_task=huggingface_task,
        huggingface_device=huggingface_device,
        huggingface_max_new_tokens=huggingface_max_new_tokens,
        huggingface_temperature=huggingface_temperature,
        huggingface_endpoint_url=hf_endpoint,
        huggingface_timeout=huggingface_timeout,
        huggingface_flux_endpoint_url=hf_flux_endpoint,
        huggingface_image_model=hf_image_model,
        huggingface_image_endpoint_url=hf_image_endpoint,
        huggingface_image_provider=hf_image_provider,
    )
